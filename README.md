# The-science-of-conductivity

## My best attempt at simplifying the extremely complex science of conductivity.


DISCLAIMER: I'm not a Quantum Physicst or an expert in semi and or super conductors and I'm purely writing this for practice and fun, mostly to refresh my own knowledge on the subject, my entire goal is to have something to link in case anyone doesn't want to read convoluted Quantum Physics manuals to understand how the most important advancement that led to modern computing works.


I'll again be TRYING my best to devide this well and categorize everything... don't bet on it ;)


# Semiconductors - the history


The history of semiconductors traces back to the early 19th century, laying the foundation for modern electronics. The journey began with the discovery of electrical properties in certain materials. In 1821, Thomas Johann Seebeck observed the thermoelectric effect, where heat applied to certain materials generated a voltage. Later, Michael Faraday and others investigated conductivity in materials like silver sulfide and selenium.

The term "semiconductor" was formally introduced in the mid-20th century, but its significance surged with the invention of the transistor in 1947 by John Bardeen, Walter Brattain, and William Shockley at Bell Labs. This pivotal breakthrough replaced bulky vacuum tubes and heralded the era of compact, efficient electronic devices. Silicon emerged as a preferred material due to its abundance and superior electronic properties. In 1958, Jack Kilby of Texas Instruments developed the first integrated circuit, a major milestone that enabled the miniaturization of electronic systems

!! Over decades, the semiconductor industry witnessed exponential growth, driven by Moore's Law, which predicted the doubling of transistors on a chip roughly every two years. This advancement led to the creation of microprocessors, memory chips, and other critical components powering computers, smartphones, and countless modern devices. Today, semiconductors are at the heart of cutting-edge technologies such as artificial intelligence, 5G, and quantum computing, shaping the future of innovation and connectivity.

Moore's law is an observation made by the co-founder of intel Gordon Moore, he predicted that the number of transistors on microchips would DOUBLE every 2 years, while the cost per transistor would decrease.

In recent years Moore's law has slowed down due to approaching the physical limitations of transistors, in a span of 5 or so decades we went from talking about millimeteres to NANOmeters, an insane feat of human engineering.

Now you may think you to yourself, why can't we just.. go smaller? And that's a damn good question, too bad I'm gonna have to go into **Quantum Physics** to really give an answer

# Quantum Physics and how it affects conducitivity 

In case you're not familiar with Quantum Physics yet (I can't really blame you) I'll take some time to explain the basics.

Throw everything you think you know about physics out the window. a paradox? impossible right? nah.

- Wave particle duality, this shows us that **stuff** can exist as both a *particle* and a *wave* at the **exact** same time, sound like nonsense? yeah, pretty much.

This only applies for teeny tiny particles like electrons, etc, sometimes these don't just act as partciles, they also act as waves, interfering with eachother and explaining phenomena like light diffraction.

- Superpositions, this gets pretty trippy. A particle can exist in multiple states or places at the same time, but only as long as we don't measure it, once this is done the particle will choose a set position.

This is actually used in Quantum Computers to get QBITs, a BIT that can be both 1 and 0, while also being any value in between these, all at the same time.

- Entanglement. Two particles can both be **linked** to eachother, entangled, so that the state of one *instantly* affects the state of the other over an infinite distance, this is another key to Quantum Computing

- Uncertainty. Do you really know anything in this field... No! You can't know both the position and speed of a particle at the same time, the more you measure the speed the less you know about the position and vice-versa (this is Heisenberg's Uncertainty Principle)


Know that you know all this.. how does this nonsense tie into transistors and exciting computing?

Well, when your average transistor is only 2 **nanometers** in size, it starts to encounters some of the same anomalies that particles do... In the way that if we get much smaller, the entire point of a transistor will be lost, instead of reliably transmitting a 1 or a 0, it'll look more like a random number generator.
